# 머신러닝 스터디 chapter1. 한눈에 보는 머신러닝

## 1.1 머신러닝이란?

데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술)

일반적인 정의 : 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야

공학적인 정의 : 어떤 작업T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업T와 성능 측정 P에 대해 경험 E로 학습한 것

## 1.2 왜 머신 러닝을 사용하는가?

**데이터 마이닝** : 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견할 수 있음

머신러닝이 뛰어난 분야

- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제->하나의 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행되도록 할 수 있음
- 전통적인 방식으로는 해결방법이 없는 복잡한 문제 : 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있음 ex)음성 인식
- 유동적인 환경 : 머신러닝은 새로운 데이터에 적응가능
- 복잡한 문제와 대량의 데이터에서 통찰 얻기(데이터 마이닝)

## 1.3 애플리케이션 사례

## 1.4 머신러닝 시스템의 종류

### 1.4.1 지도학습과 비지도 학습

사람의 감독하에 훈련하는 것인지(지도 학습) 그렇지 않은 것인지(비지도 학습)

학습하는 동안의 감독형태나 정보량에 따라 분류

1. 지도 학습(supervised learning)

   알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함

   1. 분류(classification)가 전형적인 지도 학습 작업 ex)스팸필터
   2. 회귀(recursion) : 예측변수(predictor variable)라 부르는 특성(feature)등을 사용해 타깃(target)수치를 예측

   일부 회귀 알고리즘은 분류에 사용가능, 마찬가지로 일부 분류 알고리즘도 회귀에 사용가능

   ex)분류에 널리 쓰이는 로지스틱 회귀 : 클래스에 속할 확률 출력

   지도학습 알고리즘들 : 

   - k-최근접 이웃(k-nearest neighbors)
   - 선형 회귀(linear regression)
   - 로지스틱 회귀(logistic regression)
   - 서포트 벡터 머신(support vector machine(=SVM))
   - 결정트리(decision treaa)와 랜덤 포레스트(random forest)
   - 신경망(neural networks)

2. 비지도 학습(unsupervised learning)

   훈련 데이터에 레이블이 없음->시스템이 아무런 도움 없이 학습해야함

   비지도학습 알고리즘들 : 

   - 군집(clustering) : k-평균(k-means), DBSCAN, 계층 군집 분석(hierarchical cluster analysis(=HCA)), 이상치 탐지(outlier detection)와 특이치 탐지(novelty detection), 원-클래스(one-class SVM). 아이솔레이션 포레스트(isolation forest)
   - 시각화(visualization)와 차원 축소(dimensionality reduction) : 주성분 분석(principal component analysis(=PCA)), 커널(kernel)PCA, 지역적 선형 임베딩(locally-linear embedding(=LLE)), t-SNE(t-distributed stochastic neighbor embedding)
   - 연관 규칙 학습(association rule learning) : 어프라이어리(apriori), 이클렛(eclat)

3. 준지도 학습(semisupervised learning)

   데이터에 레이블을 다는 것은 시간, 비용이 많이 들기 때문에 레이블이 없는 샘플이 많고 레이블된 샘플은 적은 경우가 많음, 일부만 레이블이 있는 데이터를 다룰 경우도 있음

   지도학습+비지도학습의 조합

   준지도학습 알고리즘 :

   - 심층 신뢰 신경망(deep belief network(=DBN)) : 여러 겹으로 쌓은 제한된 볼츠만 머신(restricted Boltzmann machine(=RBM))->비지도 학습

4. 강화 학습(reinforcement learning)

   학습하는 시스템을 에이전트라고 부르며 환경을 관찰해서 행동을 실행하고 결과로 보상(또는 벌점)을 받고 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습

   정책은 에이전트가 어떤 행동을 선택해야 할지 정의

   ex)보행 로봇, 알파고

### 1.4.2 배치 학습과 온라인 학습

입력 데이터의 스트림부터 점진적으로 학습할 수 있는 지 여부

1. 배치 학습(batch learning)

   시스템이 점진적으로 학습 불가능

   가용한 데이터를 모두 사용해 훈련시켜야함

   시간과 자원이 많이 소모되므로 오프라인에서 수행됨

   > 오프라인 학습 : 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습없이 실행->학습한 것을 단지 적용만

   배치 학습 시스템이 새로운 데이터에 대해 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련해야함, 이후 이전 시스템을 중지시키고 새 시스템으로 교체

   =>머신러닝 시스템의 전체 과정이 쉽게 자동화될 수 있어서 배치 학습 시스템도 변화에 적응가능, 데이터를 업데이트하고 시스템의 새 버전을 필요한 만큼 자주 훈련시키면 됨

   장점 : 1. 간단 2. 잘 작동

   단점 : 1. 전체 데이터셋을 사용해 훈련하는데 많은 시간필요 2. 많은 컴퓨팅 자원이 필요 3. 자원이 제한된 시스템이 스스로 학습해야 할 때 많은 양의 훈련 데이터를 나르고 학습을 위해 매일 몇시간씩 많은 자원을 사용하면 심각한 문제 유발 

2. 온라인 학습(online learning)

   데이터를 순차적으로 한 개 씩 또는 미니배치라고 부르는 작은 묶음 단위로 주입하여 시스템을 훈련

   장점 : 1. 학습 단계가 빠름 2. 비용이 적게 듦 =>시스템이 데이터가 도착하는 대로 즉시 학습 가능

   =>연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야하는 시스템에 적합

   컴퓨팅 자원이 제한된 경우에도 적합->학습이 끝난 데이터는 더는 필요하지 않으므로 버리면 됨->공간 절약

   아주 큰 데이터셋을 학습하는 시스템에도 적합->데이터 일부를 읽어들여 훈련하는 단계를 전체 데이터가 적용될 때까지 반복

   > 학습률(learning rate) : 온라인 학습 시스템의 파라미터 중 하나, 변화하는 데이터에 얼마나 빠르게 적응할 것인지
   >
   > - 학습률이 높으면 => 시스템이 데이터에 빠르게 적응 / 예전 데이터를 금방 잊음
   > - 학습률이 낮으면 => 시스템의 관성이 커져 느리게 학습 / 새로운 데이터에 있는 잡음이나 대표성 없는 데이터 포인트에 덜 민감해짐

   단점 : 1. 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소

   =>해결방법?   1. 시스템을 면밀히 모니터링, 성능감소 감지되면 즉각 학습 중지

   ​						2. 입력 데이터를 모니터링해서 비정상 데이터를 잡아내기

### 1.4.3 사례 기반 학습과 모델 기반 학습

어떻게 일반화 되는가에 따라 분류, 일반화를 위한 접근법

> 대부분의 머신러닝 작업은 예측을 만드는 것=>주어진 훈련 데이터로 학습하고 훈련 데이터에서 본 적 없는 새로운 데이터에서 좋은 예측을 만들어야함=>새로운 샘플에서 잘 작동하는 모델이 최종 목표

1. 사례 기반 학습

   시스템이 훈련 샘플을 기억함으로써 학습, 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화

2. 모델 기반 학습

   샘플들의 모델을 만들어 예측에 사용
   
   ```python
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import sklearn.linear_model
   import sklearn.neighbors
   
   #OECD life satisfaction데이터 + IMF GDP per capita데이터
   def prepare_country_stats(oecd_bli, gdp_per_capita):
       oecd_bli=oecd_bli[oecd_bli["INEQUALITY"]=="TOT"]
       oecd_bli = oecd_bli.pivot(index="Country", columns="Indicator",values="Value")
       gdp_per_capita.rename(columns={"2015" : "GDP per capita"}, inplace=True)
       gdp_per_capita.set_index("Country", inplace=True)
       full_country_stats=pd.merge(left=oecd_bli, right=gdp_per_capita,
                                   left_index=True, right_index=True)
       full_country_stats.sort_values(by="GDP per capita", inplace=True)
       remove_indices=[0,1,6,8,33,34,35]
       keep_indices=list(set(range(36))-set(remove_indices))
       return full_country_stats[["GDP per capita", "Life satisfaction"]].iloc[keep_indices]
   
   #데이터 적재
   oecd_bli=pd.read_csv("oecd_bli_2015.csv", thousands=',')
   gdp_per_capita=pd.read_csv("gdp_per_capita.csv", thousands=',',delimiter='\t',
                             encoding='latin1', na_values="n\a")
   #데이터 준비
   country_stats=prepare_country_stats(oecd_bli, gdp_per_capita)
   X=np.c_[country_stats["GDP per capita"]]
   y=np.c_[country_stats["Life satisfaction"]]
   
   '''
   #이상하게 그래프만 그리면 오류 발생 stackoverflow검색해보니 이런 사람들이 많았다. 버전 호환문제나 버그인듯
   #데이터 시각화
   country_stats.plot(kind='scatter', x="GDP per capita", y="Life satisfaction")
   plt.show()
   '''
   '''
   #선형 모델 선택    #결과 [[5.96242338]]
   model=sklearn.linear_model.LinearRegression()
   '''
   #k-최근접 이웃 회귀  #결과  [[5.76666667]]
   model=sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)
   
   #모델 훈련
   model.fit(X,y)
   
   #키프로스에 대한 예측 만들기
   X_new=[[22587]] #키프로스 1인당 GDP
   print(model.predict(X_new))
   ```
   
   > 1. 데이터 분석
   > 2. 모델 선택
   > 3. 훈련 데이터로 모델 훈련(학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터 찾음)
   > 4. 새로운 데이터에 모델을 적용, 예측(=추론,inference), 해당 모델이 일반화가 잘 되길

## 1.5 머신러닝의 주요 도전 과제

주 작업 : 학습 알고리즘을 선택해 어떤 데이터에 훈련시키는 것

문제가 될 수 있는 것 : 1. 나쁜 데이터 2. 나쁜 알고리즘

### 1.5.1  충분하지 않은 양의 훈련 데이터

> 2001년에 발표한 논문(https://homl.info/6)에 따르면 아주 간단한 모델을 포함한 여러 머신러닝 알고리즘에 충분한 데이터가 주어지면 복잡한 문제를 거의 비슷하게 잘 처리한다는 것을 보였다(!)->데이터의 중요성
>
> 하지만 여전히 작거나 중간 규모의 데이터 셋이 흔하고, 훈련 데이터를 모으는 것은 항상 쉽거나 비용이 적게드는 일이 아니므로 아직은 알고리즘을 무시하면 안됨

### 1.5.2 대표성없는 훈련 데이터

일반화가 잘되려면 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요

대표성없는 훈련 데이터를 사용하면 정확한 예측을 하지 못하게 됨

> 샘플링 잡음(sampling noise) : 우연에 의한 대표성없는 데이터, 샘플이 작을 때 발생
>
> 샘플링 편향(sampling bias) : 매우 큰 샘플이더라도 표본 추출 방법이 잘못되어 대표성을 띠지 못할 때

### 1.5.3 낮은 품질의 데이터

훈련 데이터가 에러, 이상치(outler), 잡음(ex. 성능이 낮은 측정장치로 인한)이 많다면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것

> 훈련 데이터 정제가 필요한 경우
>
> 1. 일부 샘플이 이상치라는 게 명확하면 무시하거나 수동으로 고치기
> 2. 일부 샘플에 특성 몇 개가 빠져있다면 해당 특성들을 모두 무시할 지, 해당 샘플들을 무시할지, 빠진 값을 채울지(ex.평균값으로), 해당 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬지 결정해야함

### 1.5.4 관련 없는 특성

훈련 데이터에 관련없는 특성이 적고 관련있는 특성이 충분해야 시스템이 잘 학습

> 특성 공학(feature enginerring) : 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것
>
> 1. 특성선택(feature selection) : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성 선택
> 2. 특성 추출(feature extraction) : 특성을 결합하여 더 유용한 특성으로 만듦(차원 축소 알고리즘이 도움)
> 3. 새로운 데이터를 수집해 새 특성을 만듦

### 1.5.5 훈련 데이터 과대 적합

과대 적합(overfitting) : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 것

훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생

해결 방법 : 

1. 파라미터 수가 적은 모델을 선택하거나 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화
2. 훈련 데이터를 더 많이 수집
3. 훈련 데이터의 잡음을 줄임(오류 데이터 수정, 이상치 제거,,,)

=>규제(regularization) : 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것

규제의 양은 하이퍼 파라미터(hyperparameter)가 결정하는데 모델이 아닌 학습 알고리즘의 파라미터

=>학습 알고리즘의 영향을 받지 않고 훈련 전에 미리 지정되고 훈련하는 동안에는 상수

### 1.5.6 훈련 데이터 과소 적합

과소 적합(underfitting) : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때

해결 방법 : 

1. 모델 파라미터가 더 많은 모델 선택
2. 학습 알고리즘에 더 좋은 특성을 제공(특성 공학)
3. 모델의 제약을 줄임(규제 하이퍼파라미터 감소,,,)

### 1.5.7 한걸음 물러서서

머신러닝 : 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것

머신러닝의 종류 : 지도, 비지도/배치, 온라인/사례기반, 모델기반

학습 알고리즘이 모델기반이면 훈련 셋을 모델에 맞추기 위해 모델 파라미터 조정

학습 알고리즘이 사례 기반이면 샘플을 기억하는 것이 학습, 유사도 측정을 사용하여 학습한 샘플과 새로운 샘플 비교하여 새로운 샘플에 일반화

훈련 세트가 너무 작거나, 대표성이 없는 데이터이거나, 잡음이 많고 관련없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않는다.

모델이 너무 단순(과소 적합)하거나 너무 복잡(과대 적합)하지 않아야 한다.

## 1.6 테스트와 검증

모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법 : 새로운 샘플에 실제로 적용해보는 것, 하지만 모델이 나쁘다면 고객이 불만 토로할 것

=>훈련 데이터를 훈련 세트/테스트 세트 로 나눔 훈련 세트를 사용해 모델 훈련, 테스트 세트를 사용해 모델테스트

새로운 샘플에 대한 오류 비율 : 일반화 오차(generalization error) 또는 외부 샘플 오차(out of sample error)라고 함, 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값을 얻고 이는 새로운 샘플에 모델이 얼마나 잘 작동할지 알려줌

훈련 오차가 낮지만 일반화 오차가 높으면 과대적합됐다는 뜻

보통 80%를 훈련세트에, 20%를 테스트 세트에 사용

### 1.6.1  하이퍼파라미터 튜닝과 모델 선택

모델평가는 테스트 세트를 사용하면 되고 모델 간의 성능 비교는 훈련세트로 훈련하고 테스트 세트를 사용해 얼마나 잘 일반화되는지 비교하면 됨

홀드아웃 검증(holdout validation) : 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택

=>훈련 세트 + 검증 세트 + 테스트 세트

검증 세트가 너무 많거나 적어도 문제, 그래서 검증 세트를 여러개 사용해 반복적인 교차 검증(cross validation) 수행

## 1.7연습문제

1. 머신러닝을 어떻게 정의할 수 있나요?

   데이터로부터 학습(어떤 작업에서 주어진 성능 지표가 더 나아지는 것)할 수 있는 시스템을 만드는 것

2. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해보세요

   명확한 해결책이 없는 복잡한 문제/수작업으로 만든 긴 규칙 리스트를 대체하는 경우/변화하는 환경에 적응하는 시스템을 만드는 경우/사람에게 통찰을 제공해야 하는 경우(ex. 데이터 마이닝)

3. 레이블된 훈련 세트란 무엇인가요?

   각 샘플에 대해 원하는 정답(레이블)을 담고 있는 훈련세트

4. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?

   회귀 , 분류

5. 보편적인 비지도 학습 작업 네 가지는 무엇인가요?

   군집, 시각화, 차원 축소, 연관 규칙 학습

6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?

   강화 학습

7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?

   그룹을 어떻게 정의할 지 모르는 경우 : 비슷한 고객끼리 군집으로 나누기 위해 군집 알고리즘(비지도 학습)사용

   그룹을 어떻게 정의할 지 아는 경우 : 분류 알고리즘(지도 학습)에 각 그룹에 대한 샘플 주입

8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?

   지도 학습, 알고리즘에 많은 이메일과 이에 상응하는 레이블(스팸O/X)이 제공

9. 온라인 학습 시스템이 무엇인가요?

   점진적으로 학습, 변화하는 데이터와 자율 시스템에 빠르게 적응하고 매우 많은 양의 데이털르 훈련시킬 수 있음

10. 외부 메모리 학습이 무엇인가요?

    컴퓨터의 주메모리에 들어갈 수 없는 대용량의 데이터를 다룰 수 있음

    데이터를 미니배치로 나누고 온라인 학습 기법을 사용해 학습

11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?

    사례 기반 학습 시스템은 훈련 데이터를 기억하는 학습

    새로운 샘플이 주어지면 유사도 측정을 사용해 학습된 샘플 중에서 가장 비슷한 것을 찾아 예측으로 사용

12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?

    모델은 하나 이상의 파라미터를 사용해 새로운 샘플이 주어지면 무엇을 예측할지 결정

    학습 알고리즘은 모델이 새로운 샘플에 잘 일반화되도록 이런 파라미터들의 최적값을 찾음

    하이퍼파라미터는 학습 알고리즘의 파라미터

13. 모델 기반 알고리즘이 찾는 것은 무엇인가요?성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요?예측은 어떻게 만드나요?

    새로운 샘플에 잘 일반화되기 위한 모델 파라미터의 최적값을 찾음

    훈련 데이터에서 시스템의 예측이 얼마나 나쁜지 측정하고 모델에 규제가 있다면 모델 복잡도에 대한 패널티를 더한 비용 함수를 최소화함으로써 시스템을 훈련

    학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측 함수에 새로운 샘플의 특성을 주입

14. 머신러닝의 주요 도전 과제는 무엇인가요?

    부족한 데이터, 낮은 데이터 품질, 대표성 없는 데이터, 무의미한 특성, 훈련 데이터에 과소적합된 과도하게 간단한 모델, 훈련 데이터에 과대적합된 과도하게 복잡한 모델 등

15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요?가능한 해결책 세 가지는 무엇인가요?

    훈련 데이터에 과대적합되었을 가능성이 높음

    더 많은 데이터를 모으거나, 모델을 단순화하거나, 훈련 데이터에 있는 잡음을 감소시키는 해결책이 있음

16. 테스트 세트가 무엇이고 왜 사용해야 하나요?

    실전에 배치되기 전에 모델이 새로운 샘플에 대해 만들 일반화 오차를 추정하기 위해 사용

17. 검증 세트의 목적은 무엇인가요?

    모델을 비교하는데 사용, 이를 사용해 가장 좋은 모델을 고르고 하이퍼파라미터를 튜닝

18. 훈련-개발 세트가 무엇인가요?언제 필요하고 어떻게 사용해야 하나요?

    검증, 테스트 세트에 사용되는 데이터와 훈련 세트 사이에 데이터 불일치 위험이 있을 때 사용

    훈련 세트의 일부에서 모델을 훈련하고 훈련-개발 세트와 검증세트에서 평가

19. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?

    테스트 세트에 과대적합될 위험이 있고 일반화 오차를 낙관적으로 측정하게 됨 즉, 모델을 출시하면 기대한 것보다 나쁜 성능을 낼 수 있음